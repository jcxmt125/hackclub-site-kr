<!DOCTYPE html>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="커맨드 기반 다용도 디스코드 봇의 설명서">
    <html lang="KR">

    
        <head>
        <title>다용도 디코봇 설명서</title>
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans+KR:wght@300&display=swap" rel="stylesheet">
        <style>
          body {
            font-family: 'IBM Plex Sans KR', sans-serif;;
            padding: 10px;
            line-height: 200%;
          }
        </style>
        </head>
        <body style="background-color:#202020;color:#F0F0F0">

            <h1>커맨드 기반 다용도 디스코드 봇의 설명서</h1>

            <h2>소스 코드</h2>

            <p>
              <a style="color: #effab6;" href="https://github.com/jcxmt125/memory-discord-bot">깃헙 리포지토리</a><br>
            </p>

            <h2>환경 셋업</h2>

            <p>
                우선, 리포지토리를 git clone 해주세요.<br>
                zip 파일로 다운로드 받아도 작동은 하지만, 나중에 원활한 업데이트를 위해 git clone을 추천합니다.<br>
                이 봇은 여러 파이썬 모듈을 필요로 합니다: "pip install -r requirements.txt"를 실행해 설치해주세요.<br>
                venv 안에서 하는 것을 추천합니다.<br>
                만약 리소스가 제한된 서버에 설치한다면, 우선 "pip install torch --no-cache-dir"를 실행해주세요.<br>
                혹시 리눅스 서버에서 실행시 에러가 생긴다면, "sudo apt install libzbar0"로 디펜던시를 마저 설치해보세요.<br>
                <a style="color: #effab6;" href="https://pypi.org/project/qreader/">여기</a>에서 QReader 모듈에 대한 더 많은 정보를 확인할 수 있습니다.<br>
            </p>

            <p>
                이 프로젝트에는 .env 파일이 필요합니다:<br>
                클라우드플레어 관련:
                <ul>
                    <li>CLOUDFLARE_AI_API_KEY: Cloudflare Workers AI에 접근 권한이 있는 API 키.</li>
                    <li>CLOUDFLARE_AI_GATEWAY_SLUG: Cloudflare AI gateway로 설정한 URL.</li>
                    <li>CLOUDFLARE_USER_ID: 클라우드플레어 유저 ID: 대시보드 로그인 후 브라우저에서 "dash.cloudflare.com" 뒤에 표시되는 숫자와 문자의 조합.</li>
                    <li>CLOUDFLARE_RADAR_API_KEY: Cloudflare radar 접근 권한이 있는 API 키.</li>
                </ul>
                저장 공간 관련:
                <ul>
                    <li>S3COMPAT_ENDPOINT_URL: S3 API의 엔드포인트 URL</li>
                    <li>S3KEYID: S3 키의 ID</li>
                    <li>S3SECRET: S3 키의 secret</li>
                    <li>S3_BUCKET_PUBLIC_URL: 유저들에게 보여질 S3 퍼블릭 접근 URL</li>
                    <li>S3_BUCKET_NAME: 사용할 S3 버킷의 이름</li>
                </ul>
                기타:
                <ul>
                    <li>GEMINI_API_KEY: Google의 AI studio에서 발급받으세요. 대부분의 LLM 요청이 이 키를 기본으로 사용합니다.</li>
                    <li>DISCORD_BOT_TOKEN: 디스코드 개발자 포탈에서 봇 토큰을 발급받으세요.</li>
                </ul>
            </p>

            <p>
                파이썬 모듈 외에 추가 프로그램 설치가 필요합니다:<br>
                <ul>
                    <li>ImageMagick: 설치 후, "magick" 또는 "convert"로 CLI에서 접근 가능한지 확인해주세요.</li>
                    <li>ffmpeg: 설치 후, CLI에서 접근 가능한지 확인해주세요.</li>
                </ul>
                두 개의 프로그램 모두 PATH에 있어야 합니다.
            </p>

            <h2>사용 방법</h2>

            <p>
                디스코드 개발자 포탈에서 받은 초대 URL을 이용해 봇을 서버에 초대하세요.<br>
                디렉토리 2개를 생성해주세요: "ltmemories" 와 "stmemories".<br>
                "bot.py"를 실행해주세요. 봇이 작동하기 위해 이 파일이 계속 실행중이어야 합니다.<br>
                리눅스 CLI에서는, "screen"과 같은 도구 이용을 권장합니다.<br>
                <b>느린 환경에서 봇이 켜지는데에 꽤 긴 시간이 소요될 수 있습니다.</b><br>
                봇의 디스코드 상태가 "온라인"으로 표시되는지 확인해주세요.<br>
            </p>

            <p>
                기본 프리픽스는 "?"입니다.<br>
                실행하려면 다음 커맨드를 프리픽스 뒤에 붙여 메시지로 보내세요:<br>
            </p>

            <ul>
                <li>llmreq [메시지]: LLM 백엔드로 바로 요청합니다. 텍스트만 지원합니다.</li>
                <li>dumpMemory: 유저 메모리 파일을 이 채널로 전송합니다.</li>
                <li>current: 지금 대화중인지, 그 대화가 "오래되었는지" 확인합니다.</li>
                <li>finish: 현재 대화를 끝맺습니다. 단기 기억을 요약해 장기 기억에 저장하고, 단기 기억은 삭제합니다.</li>
                <li>stmemPurge: 단기 기억을 <b>장기 기억에 저장하지 않고</b> 삭제합니다.</li>
                <li>deregisterAllMemory: <b>모든 기억을 영구적으로 삭제합니다.</b> 조심해서 사용하세요.</li>
                <li>talk [메시지]: LLM 백엔드를 이용하여 봇과 대화합니다. 오래된 대화인 경우 단기 기억이 자동으로 장기 기억으로 옮겨집니다.</li>
                <li>transcribe [첨부 파일 (여러개) (선택)]: Cloudflare AI에서 실행되는 OpenAI whisper를 이용해 오디오 파일을 텍스트로 변환합니다.</li>
                <li>ytdlAudio [URL]: YouTube에서 오디오 파일을 다운로드 합니다. (ffmpeg로 파일을 변환합니다)</li>
                <li>convert [첨부 파일 (여러개)] [타겟 포맷]: ffmpeg나 imagemagick을 MIME 타입에 따라 선택해, 타겟 포맷으로 변환합니다.</li>
                <li>ffmpeg [첨부 파일 (여러개)] [타겟 포맷]: 위와 같습니다만, ffmpeg 사용을 강제합니다.</li>
                <li>magick [첨부 파일 (여러개)] [타겟 포맷]: 위와 같습니다만 imagemagick 사용을 강제합니다.</li>
                <li>urlscan [URL]: Cloudflare radar를 이용해 URL을 스캔합니다.</li>
                <li>qrscan [첨부 파일 (여러개) (선택)]: 이미지 내의 QR 코드를 스캔합니다.</li>
                <li>publish [첨부 파일 (여러개) (선택)]: S3 버킷으로 HTML로 변환된 txt 파일을 업로드합니다.</li>
                <li>qrcode [텍스트]: QR 코드를 생성합니다. (imagemagick으로 압축해서 업로드)</li>
            </ul>

            <p>
                봇은 기본적으로 최대 25 메가바이트의 파일을 업로드할 수 있습니다.<br>
                유저의 Discord Nitro (니트로) 상태와는 관계 없습니다만, 서버의 부스트 상태가 높다면 더 큰 파일을 전송 가능할 수도 있습니다.<br>
                전송을 실패한 파일은 봇이 에러 메시지를 보내지 못하고 커맨드를 처리하지 못하게 할 수 있습니다.<br>
                VPS/클라우드 서버에서 이 봇을 구동한다면, 이그레스 비용에 대해 꼭 생각해주세요.<br>
                이미지 전송과 관련된 대부분의 기능에서, 이 봇은 webp 파일로의 변환을 통해 가능한 한 이그레스 비용을 최소화하게 디자인되어 있습니다.<br>
                이 안전장치는 convert 또는 비슷한 커맨드에 대해 적용되지 않습니다.<br>
                혹시 응답이 너무 길다면, 자동으로 .txt 파일로 메시지를 보내려 시도합니다.<br>
                일부 커맨드 사용시, 실행되는 서버의 CPU와 네트워크 성능에 따라 봇이 응답하는데 약간의 시간이 걸릴 수 있습니다.<br>
                무거운 커맨드를 사용할 때에는 주의해주세요. <b>서버 성능에 따라 봇이나 다른 프로세스가 완전히 정지될 수 있습니다.</b>
            </p>

            <p>
                봇을 업데이트하려면, git pull을 봇 디렉토리에서 실행해주세요.<br>
                업데이트로 인해 새로운 모듈이 필요할 수 있습니다. pip install -r requirements.txt를 다시 실행해주세요.<br>
            </p>

            <h2>보안과 개인 정보 보호</h2>

            <p>
                AI 기능을 사용할 때, 관련 텍스트를 구글의 Gemini API로 전송합니다.<br>
                무료 티어를 사용중이신 경우, 구글이 이 전송된 텍스트를 모델 훈련에 사용할 수 있습니다.<br>
            </p>

            <p>
                "첨부파일 선택"인 기능을 첨부파일 없이 사용하면, 봇은 몇 개 (기본적으로 5개)의 메시지를 스캔해 필요한 파일을 찾으려 합니다.<br>
                가능하다면 커맨드를 보내는 메시지에 첨부파일을 직접 첨부해주세요.<br>
                <br>
                파일을 이용한 로깅은 기본적으로 존재하지 않습니다.<br>
                일부 내용은 터미널에 출력될 수 있습니다.<br>
                <br>
                봇이 기본적으로 입력받은 코드를 실행하는 일은 없을 것입니다.<br>
                하지만, 일부 기능은 처리를 위해 봇이 실행되는 서버로 파일을 잠시 다운로드 합니다.<br>
                이 파일들은 가능한 한 빠르게 삭제됩니다.<br>
            </p>

            <h2>에러 대응 기능</h2>

            <p>
                Gemini API를 이용한 LLM 기능의 사용 중 에러가 발생하면, 일부 기능에 대해 Cloudflare AI에서 실행되는 Llama 3 모델로 대체합니다.<br>
                Gemini API의 레이트 제한에 부딪혔거나, 다른 이유로 인해 이런 상황이 발생할 수 있습니다.<br>
                이런 경우, 낮아진 성능 (속도와 품질 모두에서)를 경험할 수도 있습니다.<br>
            </p>

        </body>
    </html>