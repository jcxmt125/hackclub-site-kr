<!DOCTYPE html>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="커맨드 기반 다용도 디스코드 봇의 설명서">
    <html lang="KR">

    
        <head>
        <title>다용도 디코봇 설명서</title>
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans+KR:wght@300&display=swap" rel="stylesheet">
        <style>
          body {
            font-family: 'IBM Plex Sans KR', sans-serif;;
            padding: 10px;
            line-height: 200%;
          }
        </style>
        </head>
        <body style="background-color:#202020;color:#F0F0F0">

            <h1>커맨드 기반 다용도 디스코드 봇의 설명서</h1>

            <h2>Source code</h2>

            <p>
              <a style="color: #effab6;" href="https://github.com/jcxmt125/memory-discord-bot">깃헙 리포지토리</a><br>
            </p>

            <h2>환경 셋업</h2>

            <p>
                우선, 리포지토리를 git clone 해주세요.<br>
                zip 파일로 다운로드 받아도 작동은 하지만, 나중에 원활한 업데이트를 위해 git clone을 추천합니다.<br>
                이 봇은 여러 파이썬 모듈을 필요로 합니다: "pip install -r requirements.txt"를 실행해 설치해주세요.<br>
                venv 안에서 하는 것을 추천합니다.<br>
                만약 리소스가 제한된 서버에 설치한다면, 우선 "pip install torch --no-cache-dir"를 실행해주세요.<br>
                혹시 리눅스 서버에서 실행시 에러가 생긴다면, "sudo apt install libzbar0"로 디펜던시를 마저 설치해보세요.<br>
                <a style="color: #effab6;" href="https://pypi.org/project/qreader/">여기</a>에서 QReader 모듈에 대한 더 많은 정보를 확인할 수 있습니다.<br>
            </p>

            <p>
                이 프로젝트에는 .env 파일이 필요합니다:<br>
                클라우드플레어 관련:
                <ul>
                    <li>CLOUDFLARE_AI_API_KEY: Cloudflare Workers AI에 접근 권한이 있는 API 키.</li>
                    <li>CLOUDFLARE_AI_GATEWAY_SLUG: Cloudflare AI gateway로 설정한 URL.</li>
                    <li>CLOUDFLARE_USER_ID: 클라우드플레어 유저 ID: 대시보드 로그인 후 브라우저에서 "dash.cloudflare.com" 뒤에 표시되는 숫자와 문자의 조합.</li>
                    <li>CLOUDFLARE_RADAR_API_KEY: Cloudflare radar 접근 권한이 있는 API 키.</li>
                </ul>
                저장 공간 관련:
                <ul>
                    <li>S3COMPAT_ENDPOINT_URL: S3 API의 엔드포인트 URL</li>
                    <li>S3KEYID: S3 키의 ID</li>
                    <li>S3SECRET: S3 키의 secret</li>
                    <li>S3_BUCKET_PUBLIC_URL: 유저들에게 보여질 S3 퍼블릭 접근 URL</li>
                    <li>S3_BUCKET_NAME: 사용할 S3 버킷의 이름</li>
                </ul>
                기타:
                <ul>
                    <li>GEMINI_API_KEY: Google의 AI studio에서 발급받으세요. 대부분의 LLM 요청이 이 키를 기본으로 사용합니다.</li>
                    <li>DISCORD_BOT_TOKEN: 디스코드 개발자 포탈에서 봇 토큰을 발급받으세요.</li>
                </ul>
            </p>

            <p>
                파이썬 모듈 외에 추가 프로그램 설치가 필요합니다:<br>
                <ul>
                    <li>ImageMagick: 설치 후, "magick" 또는 "convert"로 CLI에서 접근 가능한지 확인해주세요.</li>
                    <li>ffmpeg: 설치 후, CLI에서 접근 가능한지 확인해주세요.</li>
                </ul>
                두 개의 프로그램 모두 PATH에 있어야 합니다.
            </p>

            <h2>사용 방법</h2>

            <p>
                디스코드 개발자 포탈에서 받은 초대 URL을 이용해 봇을 서버에 초대하세요.<br>
                디렉토리 2개를 생성해주세요: "ltmemories" 와 "stmemories".<br>
                "bot.py"를 실행해주세요. 봇이 작동하기 위해 이 파일이 계속 실행중이어야 합니다.<br>
                리눅스 CLI에서는, "screen"과 같은 도구 이용을 권장합니다.<br>
                <b>느린 환경에서 봇이 켜지는데에 꽤 긴 시간이 소요될 수 있습니다.</b><br>
                봇의 디스코드 상태가 "온라인"으로 표시되는지 확인해주세요.<br>
            </p>

            <p>
                기본 프리픽스는 "?"입니다.<br>
                실행하려면 다음 커맨드를 프리픽스 뒤에 붙여 메시지로 보내세요:<br>
            </p>

            <ul>
                <li>llmreq [메시지]: LLM 백엔드로 바로 요청합니다. 텍스트만 지원합니다.</li>
                <li>dumpMemory: 유저 메모리 파일을 이 채널로 전송합니다.</li>
                <li>current: 지금 대화중인지, 그 대화가 "오래되었는지" 확인합니다.</li>
                <li>finish: 현재 대화를 끝맺습니다. 단기 기억을 요약해 장기 기억에 저장하고, 단기 기억은 삭제합니다.</li>
                <li>stmemPurge: 단기 기억을 <b>장기 기억에 저장하지 않고</b> 삭제합니다.</li>
                <li>deregisterAllMemory: <b>모든 기억을 영구적으로 삭제합니다.</b> 조심해서 사용하세요.</li>
                <li>talk [메시지]: LLM 백엔드를 이용하여 봇과 대화합니다. 오래된 대화인 경우 단기 기억이 자동으로 장기 기억으로 옮겨집니다.</li>
                <li>transcribe [첨부 파일 (여러개) (선택)]: Cloudflare AI에서 실행되는 OpenAI whisper를 이용해 오디오 파일을 텍스트로 변환합니다.</li>
                <li>ytdlAudio [URL]: YouTube에서 오디오 파일을 다운로드 합니다. (ffmpeg로 파일을 변환합니다)</li>
                <li>convert [첨부 파일 (여러개)] [타겟 포맷]: ffmpeg나 imagemagick을 MIME 타입에 따라 선택해, 타겟 포맷으로 변환합니다.</li>
                <li>ffmpeg [첨부 파일 (여러개)] [타겟 포맷]: same as above, force use of ffmpeg.</li>
                <li>magick [첨부 파일 (여러개)] [타겟 포맷]: same as above, force use of imagemagick.</li>
                <li>urlscan [URL]: Scans URL with cloudflare radar.</li>
                <li>qrscan [attachment(s) (optional)]: scans for QR codes in attached image.</li>
                <li>publish [attachment(s) (optional)]: publishes a txt file as an HTML file to the S3 bucket.</li>
                <li>qrcode [text]: generates a QR code. (uses imagemagick)</li>
            </ul>

            <p>
                The bot can only send files up to 25mbs, without relation to your Discord Nitro status.<br>
                Files that fail to send may cause the bot to silently fail.<br>
                In case you are running this bot on a VPS provider, please mind the egress fee.<br>
                The bot is designed to minimize egress whenever possible, by converting images to webp.<br>
                However, this protection does not extend to usage of the convert command.<br>
                For extremely long text resopnses, the bot will try to fall back to .txt files.<br>
                When using some commands, the bot might take a bit to respond based on your server's speed (both network and CPU).<br>
                Use caution when using resource-intensove commands on resource-constrained servers. <b>It may cause the entire bot to crash.</b>
            </p>

            <p>
                To update the bot, run git pull in the directory of the bot.py file.<br>
                Updating may change dependancies. Run pip install -r requirements.txt again.<br>
            </p>

            <h2>Privacy / Security</h2>

            <p>
                When AI features are used, the bot sends the text to Google's Gemini API for analysis.<br>
                On free tier, Google may use this collected data to improve its models.<br>
            </p>

            <p>
                When "attachment optional" features are used, the bot will scan some previous messages (5 by default) to find the required file.<br>
                If possible, attach the file to the command message directly.<br>
                <br>
                Nothing is logged to a file by default.<br>
                Some things are printed to the terminal.<br>
                <br>
                The bot shouldn't be able to execute any code.<br>
                However, some features will cause files to be downloaded to the server briefly while it processes.<br>
                They will be deleted as soon as feasible.<br>
            </p>

            <h2>Fallbacks</h2>

            <p>
                The bot will fall back to Cloudflare AI's Llama 3 model in case Gemini API fails.<br>
                This may be due to a rate limit, or because something else happened.<br>
                You may notice degraded performance when this happends.<br>
            </p>

        </body>
    </html>