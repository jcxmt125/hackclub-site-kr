<!DOCTYPE html>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="능동적 디코봇의 설명서">
    <html lang="KR">

    
        <head>
        <title>능동적 디코봇 설명서</title>
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans+KR:wght@300&display=swap" rel="stylesheet">
        <style>
          body {
            font-family: 'IBM Plex Sans KR', sans-serif;;
            padding: 10px;
            line-height: 200%;
          }
        </style>
        </head>
        <body style="background-color:#202020;color:#F0F0F0">

            <h1>능동적 디코봇의 설명서</h1>

            <h2>소스 코드</h2>

            <p>
              <a style="color: #effab6;" href="https://github.com/jcxmt125/proactive-discord-bot">깃헙 리포지토리</a><br>
            </p>

            <h2>환경 셋업</h2>

            <p>
                우선, 리포지토리를 git clone 해주세요.<br>
                zip 파일로 다운로드 받아도 작동은 하지만, 나중에 원활한 업데이트를 위해 git clone을 추천합니다.<br>
                이 봇은 여러 파이썬 모듈을 필요로 합니다: "pip install -r requirements.txt"를 실행해 설치해주세요.<br>
                venv 안에서 하는 것을 추천합니다.<br>
            </p>

            <p>
                이 프로젝트에는 .env 파일이 필요합니다:<br>
                클라우드플레어 관련:
                <ul>
                    <li>CLOUDFLARE_AI_API_KEY: Cloudflare Workers AI에 접근 권한이 있는 API 키.</li>
                    <li>CLOUDFLARE_AI_GATEWAY_SLUG: Cloudflare AI gateway로 설정한 URL.</li>
                    <li>CLOUDFLARE_USER_ID: 클라우드플레어 유저 ID: 대시보드 로그인 후 브라우저에서 "dash.cloudflare.com" 뒤에 표시되는 숫자와 문자의 조합.</li>
                    <li>CLOUDFLARE_RADAR_API_KEY: Cloudflare radar 접근 권한이 있는 API 키.</li>
                </ul>
                저장 공간 관련:
                <ul>
                    <li>S3COMPAT_ENDPOINT_URL: S3 API의 엔드포인트 URL</li>
                    <li>S3KEYID: S3 키의 ID</li>
                    <li>S3SECRET: S3 키의 secret</li>
                    <li>S3_BUCKET_PUBLIC_URL: 유저들에게 보여질 S3 퍼블릭 접근 URL</li>
                    <li>S3_BUCKET_NAME: 사용할 S3 버킷의 이름</li>
                </ul>
                기타:
                <ul>
                    <li>GEMINI_API_KEY: Google의 AI studio에서 발급받으세요. 대부분의 LLM 요청이 이 키를 기본으로 사용합니다.</li>
                    <li>DISCORD_BOT_TOKEN: 디스코드 개발자 포탈에서 봇 토큰을 발급받으세요.</li>
                </ul>
            </p>

            <p>
                파이썬 모듈 외에 추가 프로그램 설치가 필요합니다:<br>
                <ul>
                    <li>ImageMagick: 설치 후, "magick" 또는 "convert"로 CLI에서 접근 가능한지 확인해주세요.</li>
                    <li>ffmpeg: 설치 후, CLI에서 접근 가능한지 확인해주세요.</li>
                </ul>
                두 개의 프로그램 모두 PATH에 있어야 합니다.
            </p>

            <h2>사용 방법</h2>

            <p>
                디스코드 개발자 포탈에서 받은 초대 URL을 이용해 봇을 서버에 초대하세요.<br>
                "bot_botmode_autoread.py"를 실행해주세요. 봇이 작동하기 위해 이 파일이 계속 실행중이어야 합니다.<br>
                리눅스 CLI에서는, "screen"과 같은 도구 이용을 권장합니다.<br>
                첫 실행시, 봇이 설정을 저장하기 위해 디렉토리를 생성합니다.<br>
                봇의 디스코드 상태가 "온라인"으로 표시되는지 확인해주세요.<br>
            </p>

            <p>
                "$initialize" 명령을 한 채널에서 실행해주세요.<br>
                이 채널이 "기본" 채널로 설정됩니다.<br>
                다른 곳에서 이 명령을 실행해 기본 채널을 변경할 수 있습니다.<br>
            </p>

            <p>
                봇은 기본적으로 최대 25 메가바이트의 파일을 업로드할 수 있습니다.<br>
                유저의 Discord Nitro (니트로) 상태와는 관계 없습니다만, 서버의 부스트 상태가 높다면 더 큰 파일을 전송 가능할 수도 있습니다.<br>
                전송을 실패한 파일은 봇이 에러 메시지를 보내지 못하고 커맨드를 처리하지 못하게 할 수 있습니다.<br>
                VPS/클라우드 서버에서 이 봇을 구동한다면, 이그레스 비용에 대해 꼭 생각해주세요.<br>
                이미지 전송과 관련된 대부분의 기능에서, 이 봇은 webp 파일로의 변환을 통해 가능한 한 이그레스 비용을 최소화하게 디자인되어 있습니다.<br>
                이 안전장치는 convert 또는 비슷한 커맨드에 대해 적용되지 않습니다.<br>
                혹시 응답이 너무 길다면, 자동으로 .txt 파일로 메시지를 보내려 시도합니다.<br>
                일부 커맨드 사용시, 실행되는 서버의 CPU와 네트워크 성능에 따라 봇이 응답하는데 약간의 시간이 걸릴 수 있습니다.<br>
            </p>

            <p>
                봇을 업데이트하려면, git pull을 봇 디렉토리에서 실행해주세요.<br>
                업데이트로 인해 새로운 모듈이 필요할 수 있습니다. pip install -r requirements.txt를 다시 실행해주세요.<br>
            </p>

            <h3>설정하기</h3>

            <p>
                $enable / $disable 로 필요한 기능의 상태를 변경할 수 있습니다.<br>
                all/AI/proactive 로 그룹별로 설정할 수 있습니다.
            </p>

            <p>
                능동적인 / 하드코딩된 기능 (proactive):<br>
                <ul>
                    <li>HelpEverywhere: 켜져있다면, 서버의 접근 가능한 모든 채널에서 아래 기능들을 이용합니다. (꺼져있다면: 기본 채널에서만 동작합니다)</li>
                    <li>ImageConversion: heic 와 avif 파일을 webp로 자동으로 변환합니다.</li>
                    <li>AudioConversion: opus 파일을 mp3로 자동으로 변환합니다.</li>
                    <li>TextPublish: 자동으로 txt 파일을 웹페이지로 게시합니다.</li>
                    <li>APNGConversion: apng 파일을 자동으로 webm으로 변환합니다.</li>
                </ul>
                <br>
                AI를 이용해 판단하는 기능 (AI):<br>
                <ul>
                    <li>AIEnabled: 기본 채널의 메시지를 IA로 분석합니다. (꺼져있다면: 아래 기능들 모두 동작하지 않습니다)</li>
                    <li>AIWebScan: Cloudflare radar를 이용해 URL이 안전한지 판단합니다.</li>
                    <li>AIMediaLoad: Youtube에서 오디오 파일을 다운로드합니다.</li>
                    <li>AIResponse: 사실적인 내용을 묻는 질문에 AI로 대답을 생성합니다.</li>
                    <li>AIImagen: Stable Diffusion을 이용해 사진을 생성합니다.</li>
                    <li>AIAudioTrancscribe: 오디오를 텍스트로 변환합니다.</li>
                </ul>
                AI 기능이 이전 메시지를 탐색하는 범위는 메시지 5개 입니다.
            </p>

            <h2>보안과 개인 정보 보호</h2>

            <p>
                AI 기능이 활성화된 경우, 봇이 기본 채널에 업로드되는 모든 메시지릐 텍스트를, 구글의 Gemini API로 전송해 분석합니다.<br>
                무료 티어를 사용중이신 경우, 구글이 이 전송된 텍스트를 모델 훈련에 사용할 수 있습니다.<br>
                #기본 등의 채널을 기본 채널로 설정하지 마세요.<br>
            </p>

            <p>
                파일을 이용한 로깅은 기본적으로 존재하지 않습니다.<br>
                일부 내용은 터미널에 출력될 수 있습니다.<br>
                <br>
                봇이 기본적으로 입력받은 코드를 실행하는 일은 없을 것입니다.<br>
                하지만, 일부 기능은 처리를 위해 봇이 실행되는 서버로 파일을 잠시 다운로드 합니다.<br>
                이 파일들은 가능한 한 빠르게 삭제됩니다.<br>
            </p>

            <h2>에러 대응 기능</h2>

            <p>
                Gemini API를 이용한 LLM 기능의 사용 중 에러가 발생하면, 일부 기능에 대해 Cloudflare AI에서 실행되는 Llama 3 모델로 대체합니다.<br>
                Gemini API의 레이트 제한에 부딪혔거나, 다른 이유로 인해 이런 상황이 발생할 수 있습니다.<br>
                이런 경우, 낮아진 성능 (속도와 품질 모두에서)를 경험할 수도 있습니다.<br>
            </p>

        </body>
    </html>